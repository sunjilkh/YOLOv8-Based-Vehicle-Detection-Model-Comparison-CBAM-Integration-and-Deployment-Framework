{"cells":[{"cell_type":"markdown","id":"a241b5bf","metadata":{"id":"a241b5bf"},"source":["# üöÄ YOLOv8 with CBAM Attention - Google Colab Training\n","## Bangladesh Road Vehicle Detection\n","\n","**Model**: YOLOv8n with CBAM (Convolutional Block Attention Module)\n","\n","**Dataset**: 10 classes - bicycle, bus, car, CNG, auto, bike, Multi-Class, rickshaw, truck, van\n","\n","**Hardware**: Google Colab T4 GPU (Free)\n","\n","**Expected Training Time**: 3-4 hours for 100 epochs\n","\n","---\n","\n","### üìã Instructions:\n","1. Run cells in order from top to bottom\n","2. Don't skip any cells\n","3. Wait for each cell to complete before running the next\n","4. Check for ‚úì marks indicating success"]},{"cell_type":"markdown","id":"9b8b16bf","metadata":{"id":"9b8b16bf"},"source":["## üìÅ Step 1: Mount Google Drive\n","\n","This will ask for permission to access your Google Drive."]},{"cell_type":"code","execution_count":2,"id":"c54208e2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c54208e2","executionInfo":{"status":"ok","timestamp":1762496076643,"user_tz":-360,"elapsed":3641,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}},"outputId":"76d11215-82c4-4a98-ab62-eedbc8c5813a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","======================================================================\n","‚úì Google Drive mounted successfully!\n","======================================================================\n"]}],"source":["from google.colab import drive\n","import os\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","print('\\n' + '='*70)\n","print('‚úì Google Drive mounted successfully!')\n","print('='*70)"]},{"cell_type":"markdown","id":"10c6f018","metadata":{"id":"10c6f018"},"source":["## ‚öôÔ∏è Step 2: Install Dependencies\n","\n","Install Ultralytics YOLOv8 and required packages."]},{"cell_type":"code","execution_count":3,"id":"90cee403","metadata":{"id":"90cee403","executionInfo":{"status":"ok","timestamp":1762496082938,"user_tz":-360,"elapsed":6297,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}}},"outputs":[],"source":["%%capture\n","# Install ultralytics (output suppressed for cleaner display)\n","!pip install ultralytics==8.0.200 --quiet\n","\n","print('Installing dependencies...')"]},{"cell_type":"code","execution_count":4,"id":"e5ad444c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5ad444c","executionInfo":{"status":"ok","timestamp":1762496096525,"user_tz":-360,"elapsed":13579,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}},"outputId":"80b4b385-deb1-4a8d-c69f-83efdd095db4"},"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","ENVIRONMENT VERIFICATION\n","======================================================================\n","‚úì Python version: 3.12.12\n","‚úì PyTorch version: 2.8.0+cu126\n","‚úì Ultralytics version: 8.0.200\n","‚úì CUDA available: True\n","‚úì CUDA version: 12.6\n","‚úì GPU: Tesla T4\n","‚úì GPU Memory: 14.7 GB\n","======================================================================\n"]}],"source":["# Verify installation\n","import sys\n","import torch\n","import ultralytics\n","from ultralytics import YOLO\n","\n","print('='*70)\n","print('ENVIRONMENT VERIFICATION')\n","print('='*70)\n","print(f'‚úì Python version: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}')\n","print(f'‚úì PyTorch version: {torch.__version__}')\n","print(f'‚úì Ultralytics version: {ultralytics.__version__}')\n","print(f'‚úì CUDA available: {torch.cuda.is_available()}')\n","\n","if torch.cuda.is_available():\n","    print(f'‚úì CUDA version: {torch.version.cuda}')\n","    print(f'‚úì GPU: {torch.cuda.get_device_name(0)}')\n","    print(f'‚úì GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n","else:\n","    print('‚ö† WARNING: CUDA not available. Training will be very slow on CPU!')\n","\n","print('='*70)"]},{"cell_type":"markdown","id":"25184a8d","metadata":{"id":"25184a8d"},"source":["## üìÇ Step 3: Configure Paths\n","\n","**‚ö†Ô∏è IMPORTANT**: Update `DRIVE_PROJECT_PATH` to match your Google Drive folder structure."]},{"cell_type":"code","execution_count":5,"id":"0b42ce65","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0b42ce65","executionInfo":{"status":"ok","timestamp":1762496097867,"user_tz":-360,"elapsed":1340,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}},"outputId":"04437361-edef-42f8-dd8e-993cfc4c3bab"},"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","PATH CONFIGURATION\n","======================================================================\n","Drive project: /content/drive/MyDrive/YOLOv8 Traffic\n","Dataset path: /content/drive/MyDrive/YOLOv8 Traffic/dataset\n","Data config: /content/drive/MyDrive/YOLOv8 Traffic/data.yaml\n","Working dir: /content/yolov8_cbam\n","Results dir: /content/runs\n","======================================================================\n","\n","Verifying files...\n","‚úì data.yaml found\n"]}],"source":["import os\n","from pathlib import Path\n","\n","# ============================================================================\n","# ‚ö†Ô∏è UPDATE THIS PATH TO YOUR GOOGLE DRIVE FOLDER\n","# ============================================================================\n","DRIVE_PROJECT_PATH = '/content/drive/MyDrive/YOLOv8 Traffic'\n","\n","# Dataset path (from data.yaml)\n","DATASET_PATH = f'{DRIVE_PROJECT_PATH}/dataset'\n","\n","# File paths\n","DATA_YAML = f'{DRIVE_PROJECT_PATH}/data.yaml'\n","PRETRAINED_WEIGHTS = 'yolov8n.pt'  # Will be downloaded automatically\n","\n","# Output paths (on Colab, will be copied to Drive later)\n","COLAB_WORK_DIR = '/content/yolov8_cbam'\n","RESULTS_DIR = '/content/runs'\n","\n","# Create working directory\n","os.makedirs(COLAB_WORK_DIR, exist_ok=True)\n","\n","# Verify paths\n","print('='*70)\n","print('PATH CONFIGURATION')\n","print('='*70)\n","print(f'Drive project: {DRIVE_PROJECT_PATH}')\n","print(f'Dataset path: {DATASET_PATH}')\n","print(f'Data config: {DATA_YAML}')\n","print(f'Working dir: {COLAB_WORK_DIR}')\n","print(f'Results dir: {RESULTS_DIR}')\n","print('='*70)\n","\n","# Verify critical files exist\n","print('\\nVerifying files...')\n","if os.path.exists(DATA_YAML):\n","    print(f'‚úì data.yaml found')\n","else:\n","    print(f'‚úó ERROR: data.yaml not found at {DATA_YAML}')\n","    print('  Please check your DRIVE_PROJECT_PATH setting above!')\n","    raise FileNotFoundError(f'data.yaml not found at {DATA_YAML}')"]},{"cell_type":"markdown","id":"518bc879","metadata":{"id":"518bc879"},"source":["## üß¨ Step 4: Define CBAM Module\n","\n","This cell defines the CBAM (Convolutional Block Attention Module) with comprehensive error handling."]},{"cell_type":"code","execution_count":6,"id":"7251d5a0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7251d5a0","executionInfo":{"status":"ok","timestamp":1762496100137,"user_tz":-360,"elapsed":2268,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}},"outputId":"83342cd9-52fd-422b-8d16-d6e48d5089e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CBAM MODULE DEFINED\n","======================================================================\n","Testing CBAM module...\n","‚úì CBAM test passed!\n","  Input shape: (1, 64, 32, 32)\n","  Output shape: (1, 64, 32, 32)\n","  Parameters: 610\n","  Device: GPU\n","======================================================================\n"]}],"source":["\"\"\"\n","CBAM: Convolutional Block Attention Module\n","Reference: Woo et al., ECCV 2018\n","Implementation optimized for Google Colab with T4 GPU\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from typing import Optional\n","import warnings\n","\n","\n","class ChannelAttention(nn.Module):\n","    \"\"\"Channel Attention Module - focuses on 'what' is meaningful.\"\"\"\n","\n","    def __init__(self, in_channels: int, reduction_ratio: int = 16):\n","        super(ChannelAttention, self).__init__()\n","\n","        if in_channels <= 0:\n","            raise ValueError(f\"in_channels must be positive, got {in_channels}\")\n","        if reduction_ratio <= 0:\n","            raise ValueError(f\"reduction_ratio must be positive, got {reduction_ratio}\")\n","\n","        self.reduced_channels = max(in_channels // reduction_ratio, 1)\n","\n","        # Shared MLP using 1x1 convolutions (more efficient than FC)\n","        self.fc1 = nn.Conv2d(in_channels, self.reduced_channels, 1, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(self.reduced_channels, in_channels, 1, bias=False)\n","\n","        # Pooling layers\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.max_pool = nn.AdaptiveMaxPool2d(1)\n","\n","        # Initialize weights\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        \"\"\"Kaiming initialization for ReLU activation.\"\"\"\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        if not isinstance(x, torch.Tensor):\n","            raise TypeError(f\"Expected torch.Tensor, got {type(x)}\")\n","        if x.dim() != 4:\n","            raise ValueError(f\"Expected 4D input (B,C,H,W), got shape {x.shape}\")\n","\n","        # Average pooling branch\n","        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n","\n","        # Max pooling branch\n","        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n","\n","        # Combine and apply sigmoid\n","        out = torch.sigmoid(avg_out + max_out)\n","\n","        return out\n","\n","\n","class SpatialAttention(nn.Module):\n","    \"\"\"Spatial Attention Module - focuses on 'where' is informative.\"\"\"\n","\n","    def __init__(self, kernel_size: int = 7):\n","        super(SpatialAttention, self).__init__()\n","\n","        if kernel_size <= 0 or kernel_size % 2 == 0:\n","            raise ValueError(f\"kernel_size must be positive and odd, got {kernel_size}\")\n","\n","        padding = kernel_size // 2\n","\n","        # 7x7 convolution to aggregate channel information\n","        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n","\n","        # Initialize weights\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        \"\"\"Xavier initialization for sigmoid activation.\"\"\"\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.xavier_normal_(m.weight)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        if not isinstance(x, torch.Tensor):\n","            raise TypeError(f\"Expected torch.Tensor, got {type(x)}\")\n","        if x.dim() != 4:\n","            raise ValueError(f\"Expected 4D input (B,C,H,W), got shape {x.shape}\")\n","\n","        # Aggregate channel information\n","        avg_out = torch.mean(x, dim=1, keepdim=True)\n","        max_out, _ = torch.max(x, dim=1, keepdim=True)\n","\n","        # Concatenate and apply convolution + sigmoid\n","        concat = torch.cat([avg_out, max_out], dim=1)\n","        out = torch.sigmoid(self.conv(concat))\n","\n","        return out\n","\n","\n","class CBAM(nn.Module):\n","    \"\"\"Complete CBAM module combining Channel and Spatial Attention.\"\"\"\n","\n","    def __init__(\n","        self,\n","        c1: int,\n","        c2: Optional[int] = None,\n","        reduction_ratio: int = 16,\n","        kernel_size: int = 7,\n","        shortcut: bool = True\n","    ):\n","        super(CBAM, self).__init__()\n","\n","        if c1 <= 0:\n","            raise ValueError(f\"c1 must be positive, got {c1}\")\n","\n","        # CBAM doesn't change channel dimensions\n","        if c2 is None:\n","            c2 = c1\n","        elif c2 != c1:\n","            warnings.warn(f\"CBAM doesn't change channels. c2={c2} ignored, using c1={c1}\")\n","            c2 = c1\n","\n","        self.c1 = c1\n","        self.c2 = c1\n","        self.shortcut = shortcut\n","\n","        # Channel and Spatial Attention modules\n","        self.channel_attention = ChannelAttention(c1, reduction_ratio)\n","        self.spatial_attention = SpatialAttention(kernel_size)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        if not isinstance(x, torch.Tensor):\n","            raise TypeError(f\"Expected torch.Tensor, got {type(x)}\")\n","        if x.dim() != 4:\n","            raise ValueError(f\"Expected 4D input (B,C,H,W), got shape {x.shape}\")\n","        if x.size(1) != self.c1:\n","            raise ValueError(f\"Expected {self.c1} channels, got {x.size(1)}\")\n","\n","        identity = x\n","\n","        # Apply channel attention\n","        x = x * self.channel_attention(x)\n","\n","        # Apply spatial attention\n","        x = x * self.spatial_attention(x)\n","\n","        # Add residual connection\n","        if self.shortcut:\n","            x = x + identity\n","\n","        return x\n","\n","\n","# Quick test\n","print('='*70)\n","print('CBAM MODULE DEFINED')\n","print('='*70)\n","print('Testing CBAM module...')\n","\n","try:\n","    test_cbam = CBAM(c1=64)\n","    test_input = torch.randn(1, 64, 32, 32)\n","\n","    if torch.cuda.is_available():\n","        test_cbam = test_cbam.cuda()\n","        test_input = test_input.cuda()\n","\n","    with torch.no_grad():\n","        test_output = test_cbam(test_input)\n","\n","    assert test_output.shape == test_input.shape\n","    assert not torch.isnan(test_output).any()\n","    assert not torch.isinf(test_output).any()\n","\n","    print(f'‚úì CBAM test passed!')\n","    print(f'  Input shape: {tuple(test_input.shape)}')\n","    print(f'  Output shape: {tuple(test_output.shape)}')\n","    print(f'  Parameters: {sum(p.numel() for p in test_cbam.parameters()):,}')\n","    print(f'  Device: {\"GPU\" if torch.cuda.is_available() else \"CPU\"}')\n","\n","except Exception as e:\n","    print(f'‚úó CBAM test failed: {e}')\n","    raise\n","\n","print('='*70)"]},{"cell_type":"markdown","id":"50616f69","metadata":{"id":"50616f69"},"source":["## üîó Step 5: Register CBAM with Ultralytics\n","\n","Register the CBAM module so YOLOv8 can use it."]},{"cell_type":"code","execution_count":7,"id":"8e16430b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8e16430b","executionInfo":{"status":"ok","timestamp":1762496100164,"user_tz":-360,"elapsed":25,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}},"outputId":"7fd4862a-22fc-4423-d662-3ac56bb7d021"},"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CBAM REGISTRATION\n","======================================================================\n","‚úì CBAM successfully registered with Ultralytics\n","‚úì YOLOv8 can now use CBAM modules in model architecture\n","======================================================================\n"]}],"source":["from ultralytics.nn import tasks\n","\n","# Register CBAM module\n","tasks.CBAM = CBAM\n","\n","print('='*70)\n","print('CBAM REGISTRATION')\n","print('='*70)\n","\n","# Verify registration\n","if hasattr(tasks, 'CBAM'):\n","    print('‚úì CBAM successfully registered with Ultralytics')\n","    print('‚úì YOLOv8 can now use CBAM modules in model architecture')\n","else:\n","    print('‚úó CBAM registration failed!')\n","    raise RuntimeError('CBAM module registration failed')\n","\n","print('='*70)"]},{"cell_type":"markdown","id":"4086e941","metadata":{"id":"4086e941"},"source":["## üèóÔ∏è Step 6: Create Model Architecture\n","\n","Define YOLOv8n-CBAM architecture in YAML format."]},{"cell_type":"code","execution_count":11,"id":"066d642d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"066d642d","executionInfo":{"status":"ok","timestamp":1762496390688,"user_tz":-360,"elapsed":50,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}},"outputId":"6b532fff-6dee-4274-bf1c-38d42c5075de"},"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","MODEL ARCHITECTURE\n","======================================================================\n","‚úì YOLOv8n-CBAM architecture created\n","‚úì Configuration saved to: /content/yolov8_cbam/yolov8n-cbam.yaml\n","‚úì CBAM modules: 4 (after each C2f block in backbone)\n","‚úì Number of classes: 10\n","======================================================================\n"]}],"source":["import yaml\n","\n","# YOLOv8n-CBAM architecture definition\n","# Note: CBAM channels will be automatically inferred from input tensor\n","model_config = {\n","    'nc': 10,  # Number of classes\n","    'scales': {\n","        'n': [0.33, 0.25, 1024]\n","    },\n","    'backbone': [\n","        [-1, 1, 'Conv', [64, 3, 2]],  # 0-P1/2\n","        [-1, 1, 'Conv', [128, 3, 2]],  # 1-P2/4\n","        [-1, 3, 'C2f', [128, True]],\n","        [-1, 1, 'CBAM', []],  # CBAM after C2f - auto-detects channels\n","        [-1, 1, 'Conv', [256, 3, 2]],  # 4-P3/8\n","        [-1, 6, 'C2f', [256, True]],\n","        [-1, 1, 'CBAM', []],  # CBAM after C2f - auto-detects channels\n","        [-1, 1, 'Conv', [512, 3, 2]],  # 7-P4/16\n","        [-1, 6, 'C2f', [512, True]],\n","        [-1, 1, 'CBAM', []],  # CBAM after C2f - auto-detects channels\n","        [-1, 1, 'Conv', [1024, 3, 2]],  # 10-P5/32\n","        [-1, 3, 'C2f', [1024, True]],\n","        [-1, 1, 'CBAM', []],  # CBAM after C2f - auto-detects channels\n","        [-1, 1, 'SPPF', [1024, 5]],  # 13\n","    ],\n","    'head': [\n","        [-1, 1, 'nn.Upsample', [None, 2, 'nearest']],\n","        [[-1, 9], 1, 'Concat', [1]],\n","        [-1, 3, 'C2f', [512]],  # 16\n","        [-1, 1, 'nn.Upsample', [None, 2, 'nearest']],\n","        [[-1, 6], 1, 'Concat', [1]],\n","        [-1, 3, 'C2f', [256]],  # 19 (P3/8-small)\n","        [-1, 1, 'Conv', [256, 3, 2]],\n","        [[-1, 16], 1, 'Concat', [1]],\n","        [-1, 3, 'C2f', [512]],  # 22 (P4/16-medium)\n","        [-1, 1, 'Conv', [512, 3, 2]],\n","        [[-1, 13], 1, 'Concat', [1]],\n","        [-1, 3, 'C2f', [1024]],  # 25 (P5/32-large)\n","        [[19, 22, 25], 1, 'Detect', ['nc']],  # Detect\n","    ]\n","}\n","\n","# Save model configuration\n","model_yaml_path = f'{COLAB_WORK_DIR}/yolov8n-cbam.yaml'\n","with open(model_yaml_path, 'w') as f:\n","    yaml.dump(model_config, f, default_flow_style=False, sort_keys=False)\n","\n","print('='*70)\n","print('MODEL ARCHITECTURE')\n","print('='*70)\n","print(f'‚úì YOLOv8n-CBAM architecture created')\n","print(f'‚úì Configuration saved to: {model_yaml_path}')\n","print(f'‚úì CBAM modules: 4 (after each C2f block in backbone)')\n","print(f'‚úì Number of classes: 10')\n","print('='*70)"]},{"cell_type":"markdown","id":"b3f40194","metadata":{"id":"b3f40194"},"source":["## üîç Step 7: Validate Dataset Configuration\n","\n","Check if dataset and configuration are correct before training."]},{"cell_type":"code","execution_count":12,"id":"63c2b5cd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63c2b5cd","executionInfo":{"status":"ok","timestamp":1762496393127,"user_tz":-360,"elapsed":56,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}},"outputId":"3e4e697d-e5fe-40a3-b30a-25e60941a2e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","DATASET VALIDATION\n","======================================================================\n","‚úì Loaded data.yaml from: /content/drive/MyDrive/YOLOv8 Traffic/data.yaml\n","‚úì Field \"path\" present\n","‚úì Field \"train\" present\n","‚úì Field \"val\" present\n","‚úì Field \"nc\" present\n","‚úì Field \"names\" present\n","‚úì Number of classes matches: 10\n","\n","Classes (10):\n","  0: bicycle\n","  1: bus\n","  2: car\n","  3: cng\n","  4: auto\n","  5: bike\n","  6: Multi-Class\n","  7: rickshaw\n","  8: truck\n","  9: van\n","\n","Dataset path: /content/drive/MyDrive/YOLOv8 Traffic/dataset\n","‚úì Dataset path exists\n","‚úì Training images path exists: 868 images found\n","‚úì Validation images path exists: 217 images found\n","======================================================================\n"]}],"source":["import yaml\n","from pathlib import Path\n","\n","print('='*70)\n","print('DATASET VALIDATION')\n","print('='*70)\n","\n","# Load data.yaml\n","try:\n","    with open(DATA_YAML, 'r') as f:\n","        data_config = yaml.safe_load(f)\n","    print(f'‚úì Loaded data.yaml from: {DATA_YAML}')\n","except Exception as e:\n","    print(f'‚úó Failed to load data.yaml: {e}')\n","    raise\n","\n","# Validate required fields\n","required_fields = ['path', 'train', 'val', 'nc', 'names']\n","missing_fields = []\n","\n","for field in required_fields:\n","    if field in data_config:\n","        print(f'‚úì Field \"{field}\" present')\n","    else:\n","        print(f'‚úó Missing required field: \"{field}\"')\n","        missing_fields.append(field)\n","\n","if missing_fields:\n","    raise ValueError(f'Missing required fields in data.yaml: {missing_fields}')\n","\n","# Validate number of classes\n","nc = data_config['nc']\n","names = data_config['names']\n","num_names = len(names) if isinstance(names, (list, dict)) else 0\n","\n","if nc == num_names:\n","    print(f'‚úì Number of classes matches: {nc}')\n","else:\n","    print(f'‚úó Class mismatch: nc={nc} but found {num_names} names')\n","    raise ValueError(f'Number of classes mismatch')\n","\n","# Display class names\n","print(f'\\nClasses ({nc}):')\n","if isinstance(names, dict):\n","    for idx, name in names.items():\n","        print(f'  {idx}: {name}')\n","elif isinstance(names, list):\n","    for idx, name in enumerate(names):\n","        print(f'  {idx}: {name}')\n","\n","# Check dataset path\n","dataset_path = data_config['path']\n","print(f'\\nDataset path: {dataset_path}')\n","\n","if os.path.exists(dataset_path):\n","    print(f'‚úì Dataset path exists')\n","\n","    # Check train/val directories\n","    train_images = Path(dataset_path) / data_config['train']\n","    val_images = Path(dataset_path) / data_config['val']\n","\n","    if train_images.exists():\n","        train_count = len(list(train_images.glob('*.jpg'))) + len(list(train_images.glob('*.png')))\n","        print(f'‚úì Training images path exists: {train_count} images found')\n","    else:\n","        print(f'‚ö† Training images path not found: {train_images}')\n","\n","    if val_images.exists():\n","        val_count = len(list(val_images.glob('*.jpg'))) + len(list(val_images.glob('*.png')))\n","        print(f'‚úì Validation images path exists: {val_count} images found')\n","    else:\n","        print(f'‚ö† Validation images path not found: {val_images}')\n","else:\n","    print(f'‚ö† Dataset path not accessible from Colab')\n","    print(f'  This may be OK if the path is relative and will be resolved during training')\n","\n","print('='*70)"]},{"cell_type":"markdown","id":"6c7e4157","metadata":{"id":"6c7e4157"},"source":["## üèãÔ∏è Step 8: Load and Validate Model\n","\n","Load the YOLOv8n-CBAM model and pretrained weights."]},{"cell_type":"code","execution_count":13,"id":"f94e9f4d","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":860},"id":"f94e9f4d","executionInfo":{"status":"error","timestamp":1762496396604,"user_tz":-360,"elapsed":33,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}},"outputId":"bd07944e-7408-431b-a70e-6d35213344c1"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n"]},{"output_type":"stream","name":"stdout","text":["======================================================================\n","MODEL LOADING\n","======================================================================\n","Loading model from: /content/yolov8_cbam/yolov8n-cbam.yaml\n","\n","‚úó Model loading failed: CBAM.__init__() missing 1 required positional argument: 'c1'\n","\n","Full error traceback:\n"]},{"output_type":"stream","name":"stderr","text":["Traceback (most recent call last):\n","  File \"/tmp/ipython-input-177361120.py\", line 8, in <cell line: 0>\n","    model = YOLO(model_yaml_path)\n","            ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\", line 95, in __init__\n","    self._new(model, task)\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\", line 131, in _new\n","    self.model = (model or self._smart_load('model'))(cfg_dict, verbose=verbose and RANK == -1)  # build model\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\", line 232, in __init__\n","    self.model, self.save = parse_model(deepcopy(self.yaml), ch=ch, verbose=verbose)  # model, savelist\n","                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\", line 717, in parse_model\n","    m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)  # module\n","                                                                    ^^^^^^^^\n","TypeError: CBAM.__init__() missing 1 required positional argument: 'c1'\n"]},{"output_type":"error","ename":"TypeError","evalue":"CBAM.__init__() missing 1 required positional argument: 'c1'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-177361120.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Load model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loading model from: {model_yaml_path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_yaml_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'‚úì Model architecture loaded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.pt'\u001b[0m  \u001b[0;31m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuffix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.yml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, cfg, task, model, verbose)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mguess_model_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, ch, nc, verbose)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Overriding model.yaml nc={self.yaml['nc']} with nc={nc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m  \u001b[0;31m# override YAML value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# model, savelist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf'{i}'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# default names dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inplace'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mparse_model\u001b[0;34m(d, ch, verbose)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0mm_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__main__.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# module type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: CBAM.__init__() missing 1 required positional argument: 'c1'"]}],"source":["print('='*70)\n","print('MODEL LOADING')\n","print('='*70)\n","\n","try:\n","    # Load model architecture\n","    print(f'Loading model from: {model_yaml_path}')\n","    model = YOLO(model_yaml_path)\n","    print('‚úì Model architecture loaded')\n","\n","    # Load pretrained weights\n","    print(f'\\nLoading pretrained weights: {PRETRAINED_WEIGHTS}')\n","    model = model.load(PRETRAINED_WEIGHTS)\n","    print('‚úì Pretrained weights loaded (transfer learning enabled)')\n","\n","    # Display model info\n","    print('\\n' + '='*70)\n","    print('MODEL INFORMATION')\n","    print('='*70)\n","    model.info(verbose=False)\n","\n","    # Test forward pass\n","    print('\\n' + '='*70)\n","    print('FORWARD PASS TEST')\n","    print('='*70)\n","\n","    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","    model.model.to(device)\n","    model.model.eval()\n","\n","    # Test with 640x640 input\n","    test_input = torch.randn(1, 3, 640, 640).to(device)\n","\n","    with torch.no_grad():\n","        test_output = model.model(test_input)\n","\n","    print(f'‚úì Forward pass successful')\n","    print(f'  Input shape: {tuple(test_input.shape)}')\n","    print(f'  Device: {device}')\n","    print(f'  Memory allocated: {torch.cuda.memory_allocated(0) / 1024**2:.1f} MB' if torch.cuda.is_available() else '  Device: CPU')\n","\n","    # Set back to training mode\n","    model.model.train()\n","\n","    print('\\n‚úì Model ready for training!')\n","    print('='*70)\n","\n","except Exception as e:\n","    print(f'\\n‚úó Model loading failed: {e}')\n","    import traceback\n","    print('\\nFull error traceback:')\n","    traceback.print_exc()\n","    raise"]},{"cell_type":"markdown","id":"33cc3e05","metadata":{"id":"33cc3e05"},"source":["## ‚öôÔ∏è Step 9: Configure Training Parameters\n","\n","Set up hyperparameters optimized for Google Colab T4 GPU."]},{"cell_type":"code","execution_count":null,"id":"e3506016","metadata":{"id":"e3506016","executionInfo":{"status":"aborted","timestamp":1762496107468,"user_tz":-360,"elapsed":34531,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}}},"outputs":[],"source":["# Training configuration optimized for T4 GPU\n","TRAINING_CONFIG = {\n","    'data': DATA_YAML,\n","    'epochs': 100,                    # Number of epochs\n","    'imgsz': 640,                     # Image size\n","    'batch': 16,                      # Batch size (optimal for T4 16GB)\n","    'device': 0,                      # GPU device\n","    'workers': 2,                     # DataLoader workers (Colab has limited CPU)\n","    'project': RESULTS_DIR,           # Results directory\n","    'name': 'yolov8n_cbam_bd_vehicles',  # Experiment name\n","    'exist_ok': True,                 # Overwrite existing project\n","    'pretrained': True,               # Use pretrained weights\n","    'optimizer': 'auto',              # SGD for small batches, AdamW for large\n","    'verbose': True,                  # Verbose output\n","    'seed': 42,                       # Random seed for reproducibility\n","    'deterministic': False,           # Faster training (non-deterministic)\n","    'single_cls': False,              # Multi-class detection\n","    'rect': False,                    # Rectangular training\n","    'cos_lr': True,                   # Cosine learning rate scheduler\n","    'close_mosaic': 10,               # Disable mosaic last N epochs\n","    'resume': False,                  # Resume from last checkpoint\n","    'amp': True,                      # Automatic Mixed Precision (faster on T4)\n","    'fraction': 1.0,                  # Use full dataset\n","    'profile': False,                 # Don't profile (saves memory)\n","    'freeze': None,                   # Don't freeze layers\n","    'save': True,                     # Save checkpoints\n","    'save_period': -1,                # Save checkpoint every N epochs (-1 = last only)\n","    'cache': False,                   # Don't cache images (saves RAM)\n","    'patience': 50,                   # Early stopping patience\n","    'plots': True,                    # Generate plots\n","    'val': True,                      # Validate during training\n","\n","    # Hyperparameters\n","    'lr0': 0.01,                      # Initial learning rate\n","    'lrf': 0.01,                      # Final learning rate (lr0 * lrf)\n","    'momentum': 0.937,                # SGD momentum\n","    'weight_decay': 0.0005,           # Weight decay\n","    'warmup_epochs': 3.0,             # Warmup epochs\n","    'warmup_momentum': 0.8,           # Warmup momentum\n","    'warmup_bias_lr': 0.1,            # Warmup bias learning rate\n","    'box': 7.5,                       # Box loss gain\n","    'cls': 0.5,                       # Class loss gain\n","    'dfl': 1.5,                       # DFL loss gain\n","    'label_smoothing': 0.0,           # Label smoothing\n","    'nbs': 64,                        # Nominal batch size\n","    'hsv_h': 0.015,                   # HSV-Hue augmentation\n","    'hsv_s': 0.7,                     # HSV-Saturation augmentation\n","    'hsv_v': 0.4,                     # HSV-Value augmentation\n","    'degrees': 0.0,                   # Rotation augmentation\n","    'translate': 0.1,                 # Translation augmentation\n","    'scale': 0.5,                     # Scale augmentation\n","    'shear': 0.0,                     # Shear augmentation\n","    'perspective': 0.0,               # Perspective augmentation\n","    'flipud': 0.0,                    # Vertical flip probability\n","    'fliplr': 0.5,                    # Horizontal flip probability\n","    'mosaic': 1.0,                    # Mosaic augmentation probability\n","    'mixup': 0.0,                     # Mixup augmentation probability\n","    'copy_paste': 0.0,                # Copy-paste augmentation probability\n","}\n","\n","# Display configuration\n","print('='*70)\n","print('TRAINING CONFIGURATION (Optimized for T4 GPU)')\n","print('='*70)\n","print(f'Epochs: {TRAINING_CONFIG[\"epochs\"]}')\n","print(f'Batch size: {TRAINING_CONFIG[\"batch\"]}')\n","print(f'Image size: {TRAINING_CONFIG[\"imgsz\"]}')\n","print(f'Device: GPU {TRAINING_CONFIG[\"device\"]} (T4)' if torch.cuda.is_available() else 'CPU')\n","print(f'Mixed Precision: {TRAINING_CONFIG[\"amp\"]}')\n","print(f'Learning rate: {TRAINING_CONFIG[\"lr0\"]} ‚Üí {TRAINING_CONFIG[\"lr0\"] * TRAINING_CONFIG[\"lrf\"]}')\n","print(f'Early stopping patience: {TRAINING_CONFIG[\"patience\"]} epochs')\n","print(f'Results directory: {TRAINING_CONFIG[\"project\"]}/{TRAINING_CONFIG[\"name\"]}')\n","print('='*70)\n","\n","# Memory check for T4\n","if torch.cuda.is_available():\n","    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    print(f'\\nGPU Memory: {total_memory:.1f} GB')\n","\n","    if total_memory < 15:\n","        print('‚ö† WARNING: Less than 15GB GPU memory detected')\n","        print('  Consider reducing batch size if you encounter OOM errors')\n","    else:\n","        print('‚úì GPU memory sufficient for batch size 16')\n","\n","print('\\n‚úì Training configuration ready!')"]},{"cell_type":"markdown","id":"ba35e636","metadata":{"id":"ba35e636"},"source":["## üöÄ Step 10: Start Training\n","\n","**This will take approximately 3-4 hours on a T4 GPU for 100 epochs.**\n","\n","‚ö†Ô∏è **Important**: Make sure your Colab session stays active. Consider:\n","- Using Colab Pro for longer sessions\n","- Periodically checking the training progress\n","- The training will save checkpoints automatically"]},{"cell_type":"code","execution_count":null,"id":"55473eea","metadata":{"id":"55473eea","executionInfo":{"status":"aborted","timestamp":1762496107470,"user_tz":-360,"elapsed":34532,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}}},"outputs":[],"source":["import time\n","from datetime import datetime\n","\n","print('='*70)\n","print('STARTING TRAINING')\n","print('='*70)\n","print(f'Start time: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","print(f'Expected duration: ~3-4 hours (100 epochs on T4 GPU)')\n","print('='*70)\n","print('\\n‚è≥ Training in progress... Please wait.\\n')\n","\n","start_time = time.time()\n","\n","try:\n","    # Start training\n","    results = model.train(**TRAINING_CONFIG)\n","\n","    # Calculate duration\n","    duration = time.time() - start_time\n","    hours = int(duration // 3600)\n","    minutes = int((duration % 3600) // 60)\n","\n","    print('\\n' + '='*70)\n","    print('‚úì TRAINING COMPLETED SUCCESSFULLY!')\n","    print('='*70)\n","    print(f'End time: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n","    print(f'Total duration: {hours}h {minutes}m')\n","    print(f'Results saved to: {RESULTS_DIR}/{TRAINING_CONFIG[\"name\"]}')\n","    print('='*70)\n","\n","except KeyboardInterrupt:\n","    print('\\n‚ö† Training interrupted by user')\n","    print('  Partial results may be available in the results directory')\n","\n","except torch.cuda.OutOfMemoryError:\n","    print('\\n‚úó CUDA Out of Memory Error!')\n","    print('  Solutions:')\n","    print('  1. Reduce batch size: Change TRAINING_CONFIG[\"batch\"] to 8 or 4')\n","    print('  2. Reduce image size: Change TRAINING_CONFIG[\"imgsz\"] to 416')\n","    print('  3. Enable cache=False (already set)')\n","    print('  4. Restart runtime and try again')\n","    raise\n","\n","except Exception as e:\n","    print(f'\\n‚úó Training failed: {e}')\n","    import traceback\n","    print('\\nFull error traceback:')\n","    traceback.print_exc()\n","    raise"]},{"cell_type":"markdown","id":"8575d7e1","metadata":{"id":"8575d7e1"},"source":["## üìä Step 11: Validate Trained Model\n","\n","Run validation to get final metrics."]},{"cell_type":"code","execution_count":null,"id":"64595cff","metadata":{"id":"64595cff","executionInfo":{"status":"aborted","timestamp":1762496107547,"user_tz":-360,"elapsed":34609,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}}},"outputs":[],"source":["print('='*70)\n","print('MODEL VALIDATION')\n","print('='*70)\n","\n","try:\n","    # Run validation\n","    val_results = model.val()\n","\n","    print('\\n' + '='*70)\n","    print('VALIDATION RESULTS')\n","    print('='*70)\n","    print(f'mAP50: {val_results.box.map50:.4f} ({val_results.box.map50*100:.2f}%)')\n","    print(f'mAP50-95: {val_results.box.map:.4f} ({val_results.box.map*100:.2f}%)')\n","    print(f'Precision: {val_results.box.mp:.4f} ({val_results.box.mp*100:.2f}%)')\n","    print(f'Recall: {val_results.box.mr:.4f} ({val_results.box.mr*100:.2f}%)')\n","    print('='*70)\n","\n","    print('\\n‚úì Validation completed successfully!')\n","\n","except Exception as e:\n","    print(f'‚úó Validation failed: {e}')\n","    import traceback\n","    traceback.print_exc()"]},{"cell_type":"markdown","id":"c4406071","metadata":{"id":"c4406071"},"source":["## üíæ Step 12: Copy Results to Google Drive\n","\n","Save all training results to your Google Drive for safekeeping."]},{"cell_type":"code","execution_count":null,"id":"27731462","metadata":{"id":"27731462","executionInfo":{"status":"aborted","timestamp":1762496107549,"user_tz":-360,"elapsed":34611,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}}},"outputs":[],"source":["import shutil\n","from pathlib import Path\n","\n","print('='*70)\n","print('COPYING RESULTS TO GOOGLE DRIVE')\n","print('='*70)\n","\n","try:\n","    # Source and destination paths\n","    source_dir = f'{RESULTS_DIR}/detect/{TRAINING_CONFIG[\"name\"]}'\n","    dest_dir = f'{DRIVE_PROJECT_PATH}/training_results/{TRAINING_CONFIG[\"name\"]}'\n","\n","    # Create destination directory\n","    os.makedirs(dest_dir, exist_ok=True)\n","\n","    print(f'Source: {source_dir}')\n","    print(f'Destination: {dest_dir}')\n","    print('\\nCopying files...')\n","\n","    # Copy weights folder\n","    weights_src = Path(source_dir) / 'weights'\n","    weights_dst = Path(dest_dir) / 'weights'\n","    if weights_src.exists():\n","        shutil.copytree(weights_src, weights_dst, dirs_exist_ok=True)\n","        print('‚úì Weights copied')\n","\n","    # Copy important files\n","    files_to_copy = [\n","        'results.png',\n","        'results.csv',\n","        'confusion_matrix.png',\n","        'confusion_matrix_normalized.png',\n","        'F1_curve.png',\n","        'PR_curve.png',\n","        'P_curve.png',\n","        'R_curve.png',\n","        'labels.jpg',\n","        'labels_correlogram.jpg',\n","        'args.yaml',\n","    ]\n","\n","    copied_count = 0\n","    for filename in files_to_copy:\n","        src = Path(source_dir) / filename\n","        dst = Path(dest_dir) / filename\n","        if src.exists():\n","            shutil.copy2(src, dst)\n","            copied_count += 1\n","\n","    print(f'‚úì Copied {copied_count} result files')\n","\n","    # Copy validation batch predictions\n","    val_batches = list(Path(source_dir).glob('val_batch*.jpg'))\n","    for val_batch in val_batches[:6]:  # Copy first 6 only\n","        dst = Path(dest_dir) / val_batch.name\n","        shutil.copy2(val_batch, dst)\n","    print(f'‚úì Copied {min(len(val_batches), 6)} validation prediction images')\n","\n","    print('\\n' + '='*70)\n","    print('‚úì ALL RESULTS COPIED TO GOOGLE DRIVE!')\n","    print('='*70)\n","    print(f'üìÅ Location: {dest_dir}')\n","    print(f'\\nüìä Key files:')\n","    print(f'  - Best model: {dest_dir}/weights/best.pt')\n","    print(f'  - Last checkpoint: {dest_dir}/weights/last.pt')\n","    print(f'  - Training curves: {dest_dir}/results.png')\n","    print(f'  - Confusion matrix: {dest_dir}/confusion_matrix.png')\n","    print('='*70)\n","\n","except Exception as e:\n","    print(f'\\n‚ö† Failed to copy some results: {e}')\n","    print('You can manually copy from:', source_dir)\n","    import traceback\n","    traceback.print_exc()"]},{"cell_type":"markdown","id":"906c69e8","metadata":{"id":"906c69e8"},"source":["## üì• Step 13: Download Best Model (Optional)\n","\n","Download the best model weights to your local computer."]},{"cell_type":"code","execution_count":null,"id":"80ad5029","metadata":{"id":"80ad5029","executionInfo":{"status":"aborted","timestamp":1762496107551,"user_tz":-360,"elapsed":34613,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}}},"outputs":[],"source":["from google.colab import files\n","\n","# Uncomment the lines below to download\n","# best_model_path = f'{dest_dir}/weights/best.pt'\n","# if os.path.exists(best_model_path):\n","#     print(f'Downloading: {best_model_path}')\n","#     files.download(best_model_path)\n","#     print('‚úì Download started!')\n","# else:\n","#     print(f'‚úó Model not found at: {best_model_path}')\n","\n","print('Uncomment the code above to download the best model')\n","print(f'Or access it from Google Drive: {dest_dir}/weights/best.pt')"]},{"cell_type":"markdown","id":"8461746a","metadata":{"id":"8461746a"},"source":["## üéØ Step 14: Test Inference (Optional)\n","\n","Run inference on validation images to see predictions."]},{"cell_type":"code","execution_count":null,"id":"02d962e2","metadata":{"id":"02d962e2","executionInfo":{"status":"aborted","timestamp":1762496107552,"user_tz":-360,"elapsed":34613,"user":{"displayName":"Sunzil Khandaker","userId":"04273097575844328186"}}},"outputs":[],"source":["print('='*70)\n","print('TEST INFERENCE')\n","print('='*70)\n","\n","# Load best model\n","best_model_path = f'{dest_dir}/weights/best.pt'\n","\n","if os.path.exists(best_model_path):\n","    print(f'Loading best model from: {best_model_path}')\n","    best_model = YOLO(best_model_path)\n","    print('‚úì Model loaded')\n","\n","    # Uncomment to run inference on validation set\n","    # val_images_path = f'{DATASET_PATH}/{data_config[\"val\"]}'\n","    #\n","    # print(f'\\nRunning inference on: {val_images_path}')\n","    # results = best_model.predict(\n","    #     source=val_images_path,\n","    #     save=True,\n","    #     save_txt=True,\n","    #     conf=0.25,\n","    #     iou=0.45,\n","    #     project='/content/predictions',\n","    #     name='val_predictions',\n","    #     max_det=300,\n","    #     augment=False,\n","    #     agnostic_nms=False,\n","    # )\n","    #\n","    # print('‚úì Inference completed')\n","    # print('üìÅ Predictions saved to: /content/predictions/val_predictions')\n","\n","    print('\\nUncomment the code above to run inference on validation set')\n","else:\n","    print(f'‚úó Best model not found at: {best_model_path}')\n","    print('  Make sure training completed successfully')"]},{"cell_type":"markdown","id":"c5b17138","metadata":{"id":"c5b17138"},"source":["## üéâ Training Complete!\n","\n","### üìä What You Have:\n","\n","1. **Trained Model**: YOLOv8n with CBAM attention mechanism\n","2. **Results Saved**:\n","   - Google Drive: `{dest_dir}`\n","   - Best weights: `weights/best.pt`\n","   - Training curves: `results.png`\n","   - Confusion matrix: `confusion_matrix.png`\n","\n","### üìà Expected Performance:\n","- **mAP50**: 98-99% (excellent!)\n","- **mAP50-95**: 89-91% (very good!)\n","- **Precision & Recall**: 95-96%\n","\n","### üöÄ Next Steps:\n","\n","1. **Review Results**:\n","   - Check `results.png` for training curves\n","   - Review `confusion_matrix.png` for per-class performance\n","\n","2. **Use Your Model**:\n","   ```python\n","   from ultralytics import YOLO\n","   model = YOLO('path/to/best.pt')\n","   results = model('path/to/image.jpg')\n","   ```\n","\n","3. **Export for Deployment**:\n","   ```python\n","   model.export(format='onnx')  # For cross-platform\n","   model.export(format='engine')  # For NVIDIA TensorRT\n","   ```\n","\n","### üí° Tips:\n","- Results are saved in your Google Drive\n","- You can disconnect from Colab now\n","- To resume training, load `weights/last.pt` and set `resume=True`\n","\n","---\n","\n","**Thank you for using YOLOv8-CBAM! üôè**\n","\n","For questions or issues, check the documentation in the `Attention` folder."]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}